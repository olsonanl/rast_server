[%#
	Slurm submission template for submitting RAST job into an NFS-based installation
-%]
#!/bin/bash
#SBATCH --account [% sbatch_account %]
#SBATCH --job-name [% sbatch_job_name %]
#SBATCH --mem [% sbatch_job_mem %]
#SBATCH --nodes 1-1 --ntasks [% n_cpus %]
#SBATCH --export NONE
#SBATCH -p [% partition %]

#SBATCH --output [% sbatch_output %]
#SBATCH --err [% sbatch_error %]
#SBATCH --time [% sbatch_time %]

export P3_ALLOCATED_MEMORY="${SLURM_MEM_PER_NODE}M"
export P3_ALLOCATED_CPU=$SLURM_JOB_CPUS_PER_NODE
export OVERRIDE_NSLOTS=$SLURM_JOB_CPUS_PER_NODE

#
# Emulate SGE variables for the SEED code that assumes SGE.
#
export SGE_TASK_ID=$SLURM_ARRAY_TASK_ID
export SGE_TASK_FIRST=$SLURM_ARRAY_TASK_MIN
export SGE_TASK_LAST=$SLURM_ARRAY_TASK_MAX

[% IF environment_config -%]
[% FOR ent IN environment_config -%]
[% ent %]
[% END -%]
[% END -%]

top=`pwd`

[% FOR job IN jobs -%]

rast_jobdir=[% job.directory %]

export WORKDIR=$rast_jobdir/slurm_work/$SLURM_JOB_ID
mkdir -p $WORKDIR
cd $WORKDIR

script_name="run_[% application %].[% job.id %].$SLURM_JOB_ID"

cat > $script_name <<"EOF"
#!/bin/bash -x

source [% rast_installation %]/user-env.sh

[% IF application == "annotate" -%]

batch_rast [% FOR phase IN phases %] --phase [% phase %] [% END %] [% job.directory %]

[% ELSIF application == "close_strains" -%]

svr_CS -d [% close_strains_dir %] --fill-in-refs

[% ELSIF application == "replicate" -%]

replicate_job [% job.old_directory %] [% job.directory %]

[% END -%]

EOF
chmod +x $script_name

export TMPDIR=/disks/tmp
export TEMPDIR=/dsks/tmp

./$script_name &

pid_[% job.id %]=$!
echo "job [% job.id %] has pid $pid_[% job.id %]"

[% END -%]

cd $top

[% FOR job IN jobs -%]

pid=$pid_[% job.id %]
echo "Wait for task [% job.id %] $pid"
wait $pid
rc_[% job.id %]=$?
echo "Job [% job.id %] exited with $rc_[% job.id %]"

[% END -%]

[% IF jobs.size == 1 -%]
exit $rc_[% jobs.0.id %]
[% ELSE -%]
exit 0
[% END -%]

